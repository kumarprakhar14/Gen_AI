{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3927221",
   "metadata": {},
   "source": [
    "# ðŸŽ¨ Welcome to UNIT I: Generative AI!\n",
    "## The Paradigm Shift\n",
    "**What you've been doing (Discriminative Models):**\n",
    "```bash\n",
    "Input: Image of digit\n",
    "Output: \"This is a 7\" (classification)\n",
    "\n",
    "Question: \"What is this?\"\n",
    "```\n",
    "\n",
    "**What we're about to do (Generative Models):**\n",
    "```bash\n",
    "Input: Random noise / latent code\n",
    "Output: Brand new image of digit\n",
    "\n",
    "Question: \"Can you create this?\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1794fe49",
   "metadata": {},
   "source": [
    "## Today's Mission: Your First Generative Model\n",
    "We're building an Autoencoder - the gateway to generative AI!\n",
    "```bash\n",
    "Autoencoder:\n",
    "Input Image â†’ Encoder â†’ Compressed Code â†’ Decoder â†’ Reconstructed Image\n",
    "\n",
    "Goal: Make output look like input!\n",
    "Magic: The \"compressed code\" learns meaningful representations\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e7c029",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Today's Plan (1.5 hours)\n",
    "### Part 1: Theory - Generative vs Discriminative (30 min)\n",
    "- What makes a model \"generative\"?\n",
    "- Latent spaces (the secret sauce!)\n",
    "- Why autoencoders are cool\n",
    "\n",
    "### Part 2: Build Your First Autoencoder (60 min)\n",
    "- Code-first approach\n",
    "- Encoder: Compress 28Ã—28 â†’ 32 dimensions\n",
    "- Decoder: Decompress 32 â†’ 28Ã—28\n",
    "- Train and see reconstructions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9df529",
   "metadata": {},
   "source": [
    "### ðŸ“š Part 1: Generative vs Discriminative (20-25 min)\n",
    "[Read the doc](../../docs/Introduction-to-GenAI.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dacc3bf",
   "metadata": {},
   "source": [
    "### ðŸš€ Part 2: Build Your First Autoencoder!\n",
    "Challenge Mode Activated! Let's compress and reconstruct MNIST digits! ðŸŽ¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123d6a24",
   "metadata": {},
   "source": [
    "**Quick Reference Card** \n",
    "```py\n",
    "# Data preprocessing\n",
    "x.reshape(-1, 784)  # Flatten (28,28) â†’ (784,)\n",
    "x.astype('float32') / 255.0  # Normalize\n",
    "\n",
    "# Autoencoder architecture\n",
    "keras.Sequential([\n",
    "    # Encoder (compress)\n",
    "    Dense(256, activation='relu', input_shape=(784,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(32, activation='relu'),  # â† Bottleneck (latent!)\n",
    "    \n",
    "    # Decoder (expand)\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(784, activation='sigmoid'),  # â† Output [0,1]\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train (KEY: input = target!)\n",
    "model.fit(x_train, x_train, epochs=10, batch_size=256, \n",
    "          validation_data=(x_test, x_test))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c254b1",
   "metadata": {},
   "source": [
    "### ðŸ” What to Watch For\n",
    "\n",
    "1. Training loss should decrease steadily\n",
    "\n",
    "- Epoch 1: ~0.15-0.20\n",
    "- Epoch 10: ~0.09-0.10\n",
    "\n",
    "\n",
    "2. Reconstructions will be slightly blurry (normal!)\n",
    "\n",
    "- Not pixel-perfect\n",
    "- But clearly recognizable\n",
    "\n",
    "\n",
    "3. Different from CNN:\n",
    "\n",
    "- No labels needed!\n",
    "- Input = Output\n",
    "- Loss is reconstruction error, not classification error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8680e0c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Gen_AI (3.12.10) (Python 3.12.10)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/kumar/Desktop/KP Programming/AI/Gen_AI/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "AUTOENCODER CHALLENGE: Build Your First Generative Model!\n",
    "\n",
    "Goal: Compress MNIST digits from 784 â†’ 32 dimensions â†’ 784 pixels\n",
    "      Watch the magic of reconstruction!\n",
    "\n",
    "Architecture:\n",
    "Input (784) â†’ Dense(256) â†’ Dense(128) â†’ Dense(32) â†’ Dense(128) â†’ Dense(256) â†’ Output(784)\n",
    "              â†‘________ENCODER________â†‘  LATENT  â†‘_________DECODER________â†‘\n",
    "\n",
    "Your job: Fill in the TODOs!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd1d8c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c0b67a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PART 1: LOAD & PREPROCESS DATA\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97cc2d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Loading MNIST Dataset\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Loading MNIST Dataset\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9ea79c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60000\n",
      "Test samples: 10000\n",
      "Image shape: (28, 28)\n"
     ]
    }
   ],
   "source": [
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(f\"Training samples: {len(x_train)}\")\n",
    "print(f\"Test samples: {len(x_test)}\")\n",
    "print(f\"Image shape: {x_train[0].shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gen_AI (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
